<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8" />

  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css">
  <title></title>

  <style>
    table {
      border-collapse: collapse;
      border: 2px solid black;
      margin: 20px 0;
    }

    th, td {
      border: 1px solid black;
      padding: 8px 12px;
      text-align: center;
    }

    th {
      background-color: #f0f0f0;
      font-weight: bold;
    }
  </style>


</head>
<body>
<header>
</header>
<main id="app">

  <h1>kbt18.github.io</h1>

  <h2>The c++ Memory Model</h2>

  <h3>The Atomic Operations</h3>

  <ul>
    <li>
      Store operations, which can have <code>memory_order_relaxed</code>,
      <code>memory_order_release</code>, or
      <code>memory_order_seq_cst</code> ordering
    </li>
    <li>
      Load operations, which can have <code>memory_order_relaxed</code>,
      <code>memory_order_consume</code>,
      <code>memory_order_acquire</code>, or
      <code>memory_order_seq_cst</code> ordering
    </li>
    <li>
      Read-modify-write operations, which can have
      <code>memory_order_relaxed</code>,
      <code>memory_order_consume</code>,
      <code>memory_order_acquire</code>,
      <code>memory_order_release</code>,
      <code>memory_order_acq_rel</code>, or
      <code>memory_order_seq_cst</code> ordering
    </li>
  </ul>

  <h3>Memory Orderings</h3>

  <h4>Sequentially Consistent Ordering</h4>
  <p>
    Under sequentially consistent memory ordering, all threads see the same order of operations, or alternatively, all threads see the same global state. This is the default memory ordering for all atomic operations in c++ so does not need stating explicitly.
  </p>

  <p>
    Consider the following program consisting of two threads. <code>t1</code> writes to <code>x</code> and reads from <code>y</code>. <code>t2</code> writes to <code>y</code> and reads from <code>x</code>. We then assert that both of the reads are not zero.
  </p>

  <pre class="line-numbers"><code class="language-cpp">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;cassert&gt;

std::atomic&lt;int&gt; x{0}, y{0};
int r1 = 0, r2 = 0;

int main() {
  std::thread t1([] {
    x.store(1, std::memory_order_seq_cst);  // A
    r1 = y.load(std::memory_order_seq_cst); // B
  });

  std::thread t2([] {
    y.store(1, std::memory_order_seq_cst);  // C
    r2 = x.load(std::memory_order_seq_cst); // D
  });

  t1.join();
  t2.join();

  assert(!(r1 == 0 && r2 == 0));
}</code></pre>

  <p>
    The threads cannot both read zero and so the assertion <strong>never</strong> fails. If t1 writes to x before the read in t2, t2 must read that value, and vice versa if t2 writes to y before the read in t1. This might not come as a surprise since this is the mental model
    we are used to when writing concurrent code with atomics. <code>memory_order_seq_cst</code> is the simplest memory order to reason about.
  </p>

  <p><code>memory_order_seq_cst</code> is the most expensive of all the memory orderings. This becomes of particular concern on non x86/64 hardware where there is no hardware level implementation for sequentially consistent ordering.</p>

  <p>
    To clearly see why we can say the assertion never fails, we can explicitly list all the possible global orderings of operations and the corresponding values r1 and r2. No possible valid order of operations can result in r1 and r2 both being zero.
  </p>

  <table>
    <tr>
      <th>Ordering</th>
      <th>r1</th>
      <th>r2</th>
    </tr>
    <tr>
      <td>A B C D</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>A C B D</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>A C D B</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>C D A B</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>C A D B</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>C A B D</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </table>

  <h3>Non-Sequentially Consistent Memory Orderings</h3>
  <h4>Relaxed Ordering</h4>
  <p>We now turn to the strange world of non-sequentially consistent memory ordering, where different threads don't have to agree on a global order of operations. We'll use the same example as before, but with <code>memory_order_relaxed</code></p>
  <p>In our nice mental model of concurrent programming, all operations are neatly interleaved so you could in theory write them all down as a single global order of operations. Throw this mental model out the window!</p>
  <p><code>memory_order_relaxed</code> is the least restrictive ordering. Atomic operations are still atomic, but there are no synchronization or visibility guarantees between threads. If thread A writes to a variable, there is no guarantee that thread B will see that write. On x86 we can generally rely on writes being seen eventually because of the strong memory model on x86.</p>

  <pre class="line-numbers"><code class="language-cpp">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;cassert&gt;

std::atomic&lt;int&gt; x{0}, y{0};
int r1 = 0, r2 = 0;

int main() {
  std::thread t1([] {
    x.store(1, std::memory_order_relaxed);  // A
    r1 = y.load(std::memory_order_relaxed); // B
  });

  std::thread t2([] {
    y.store(1, std::memory_order_relaxed);  // C
    r2 = x.load(std::memory_order_relaxed); // D
  });

  t1.join();
  t2.join();

  assert(!(r1 == 0 && r2 == 0));
}</code></pre>

  <p>This assertion can sometimes fail. This violates the nice mental model we have of concurrent programming. How can r1 and r2 both read zero? Did the writes to x and y somehow get skipped? What's actually happening is that t2 sees a different version of reality to t1. This is what we mean when we say there is no longer a single global order of operations.</p>

  <p>t1 writes to x and then reads from y. When t1 reads from y, it can read an older value even if t2 has already written to y. This is possible because each core can buffer its own stores.</p>

  <p>Even though in t1 the store to x happens before the load from y in program order, there is no guarantee that t2 will observe the store to x before performing its load. Likewise for t1 observing t2â€™s store.</p>

  <p>The only requirement is that if a thread sees a particular value of an atomic variable, it can't then see a previous value on subsequent reads. It can only see the value it already read, or values that were written after.</p>

  <!-- TODO: animation that shows relaxed ops. Section on when to use relaxed ordering. -->

  <h4>Acquire-Release Ordering</h4>

  <p>Aquire-release sits somewhere between relaxed and sequentially consistent, in terms of the guarantees it offers</p>

  <p>read = acquire, store = release, read-modify-write can be store, release or acquire release.</p>
  <p>acquire should be paired with release</p>
  <p>can also be paired with sequentially consistent</p>
  <p>synchronisation is between the threads that contain the acquire, release pair. Other threads won't sync.</p>

  <pre class="line-numbers"><code class="language-cpp">#include &lt;atomic&gt;
    #include &lt;thread&gt;
    #include &lt;cassert&gt;

    std::atomic&lt;bool&gt; ready{false};
    int data = 0;

    void producer() {
    data = 42;                               // (1) normal write
    ready.store(true, std::memory_order_release); // (2) publish
    }

    void consumer() {
    while (!ready.load(std::memory_order_acquire)) {
    ; // spin
    }
    assert(data == 42);                      // (3) guaranteed
    }

    int main() {
    std::thread t1(producer);
    std::thread t2(consumer);
    t1.join();
    t2.join();
    }
  </code></pre>

  <p>This is all well and good, but we could have just used sequentially consistent ordering here and got the same outcome. To see how the behavior differs from sequentially consistent, we add more threads.</p>

  <pre class="line-numbers"><code class="language-cpp">
    #include &lt;atomic&gt;
    #include &lt;thread&gt;
    #include &lt;cassert&gt;
    #include &lt;iostream&gt;

    std::atomic&lt;bool&gt; x{false};
    std::atomic&lt;bool&gt; y{false};

      int r1 = 0;
      int r2 = 0;

    void t1() {
    x.store(true, std::memory_order_release);
    }

    void t2() {
    y.store(true, std::memory_order_release);
    }

    void t3() {
    // Observer A
    while (!x.load(std::memory_order_acquire)) {}
    r1 = y.load(std::memory_order_acquire);
    }

    void t4() {
    // Observer B
    while (!y.load(std::memory_order_acquire)) {}
    r2 = x.load(std::memory_order_acquire);
    }

    int main() {
    std::thread a(t1), b(t2), c(t3), d(t4);
    a.join(); b.join(); c.join(); d.join();

    assert(r1!=0 && r2!=0);
    }
  </code></pre>

  <p>The assert <b>can</b> fire here.</p>
  <p>r1 and r2 can both be zero. t1 syncs with t3. t2 syncs with t4. There is no synchronisation between t2 and t3, or t1 and t4.</p>
  <p>Synchronisation happens on the acquire-release pair between two threads.</p>

  <h4>acquire release and non-atomic operations</h4>
  <p>Aquire-release can be used to synchronise non-atomic operations.</p>
  <pre class="line-numbers"><code class="language-cpp">
  #include &lt;atomic&gt;
  #include &lt;thread&gt;
  #include &lt;cassert&gt;

  int data{0};
  std::atomic&lt;bool&gt; ready{false};

  void producer() {
      //non-atomic write
      data = 42;

      // Publish the data
      ready.store(true, std::memory_order_release);
  }

  void consumer() {
      // Spin until the data is published
      while (!ready.load(std::memory_order_acquire)) {
          // busy-wait
      }

      // After acquire, all writes before the release are visible
      assert(data == 42);
  }

  int main() {
      std::thread t1(producer);
      std::thread t2(consumer);

      t1.join();
      t2.join();
  }

  </code></pre>

  <p>There is no data race on the <code>data</code> variable because the consumer must wait until the producer signals ready.</p>

  <p>If you have a more complex use case where the proucer updates data many times, use an atomic with relaxed ordering. The release-acquire will synchronise the relaxed operations such that any relaxed write that happens before the release in the producer thread must happen before any relaxed read in the acquire in the consumer thread.</p>

  <h4>The Release Sequence</h4>
  <p>Still can't find a good definition.</p>

  <h4>memory_order_consume</h4>
  <p>This is deprecated in c++26. The majority of compilers implement it as memory_order_aquire anyway.</p>

  <h2>X86 TSO</h2>

  <p>Just because something might work on TSO, it's still preferable to use the weakest ordering that is necessary.</p>

</main>
<footer>
</footer>


<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script>

</body>
</html>
